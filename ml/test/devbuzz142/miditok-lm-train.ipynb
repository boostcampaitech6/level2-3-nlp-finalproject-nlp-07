{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets transformers\n",
    "!pip install miditok\n",
    "!pip install symusic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/lakh-gpt2/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from miditok import MMM, TokenizerConfig\n",
    "from miditok.classes import Event, TokSequence\n",
    "from miditok.pytorch_data import DatasetTok, DataCollator\n",
    "from miditok.constants import MIDI_INSTRUMENTS, MMM_DENSITY_BINS_MAX, TIME_SIGNATURE\n",
    "from miditok.midi_tokenizer import MIDITokenizer\n",
    "from miditok.utils import compute_ticks_per_bar, compute_ticks_per_beat\n",
    "\n",
    "import numpy as np\n",
    "from symusic import Note, Score, Tempo, TimeSignature, Track\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 21)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jazz_midi_paths = list(Path(\"jazz-chunked\").glob(\"**/*.mid\"))[:30]\n",
    "ym_midi_paths = list(Path(\"../ym-test/chunks\").glob(\"**/*.mid\"))\n",
    "\n",
    "len(jazz_midi_paths), len(ym_midi_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 3, 19, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split MIDI paths in train/valid/test sets\n",
    "\n",
    "from random import shuffle\n",
    "\n",
    "def split_midi_paths_train_valid(midi_paths, valid_ratio=0.1):\n",
    "    total_num_files = len(midi_paths)\n",
    "    num_files_valid = round(total_num_files * valid_ratio)\n",
    "    shuffle(midi_paths)\n",
    "    midi_paths_valid = midi_paths[:num_files_valid]\n",
    "    midi_paths_train = midi_paths[num_files_valid:]\n",
    "    return midi_paths_train, midi_paths_valid\n",
    "\n",
    "jazz_midi_paths_train, jazz_midi_paths_valid = split_midi_paths_train_valid(jazz_midi_paths)\n",
    "ym_midi_paths_train, ym_midi_paths_valid = split_midi_paths_train_valid(ym_midi_paths)\n",
    "\n",
    "len(jazz_midi_paths_train), len(jazz_midi_paths_valid), len(ym_midi_paths_train), len(ym_midi_paths_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a multitrack tokenizer configuration, read the doc to explore other parameters\n",
    "\n",
    "config = TokenizerConfig(\n",
    "    num_velocities=16, \n",
    "    use_chords=True, \n",
    "    use_programs=True,\n",
    "    use_pitch_intervals=True\n",
    "    )\n",
    "\n",
    "TEXTER_NAME = MMM # MMM 토크나이저 사용\n",
    "# TOKENIZER_NAME = MuMIDI # MuMIDI 토크나이저 사용\n",
    "texter = TEXTER_NAME(config)\n",
    "texter.add_to_vocab('Genre_Jazz')\n",
    "texter.add_to_vocab('Genre_Ym')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "vocab.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 1.91MB/s]\n",
      "merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 956kB/s]\n",
      "tokenizer.json: 100%|██████████| 1.36M/1.36M [00:00<00:00, 2.88MB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15496, 11, 616, 3290, 318, 13779]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"Hello, my dog is cute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Track_Start Program_-1 NoteDensity_4 Bar_Start PitchDrum_35 Velocity_79 Duration_0.2.8 PitchDrum_49 Velocity_87 Duration_0.2.8 PitchDrum_51 Velocity_95 Duration_0.2.8 TimeShift_0.6.8 PitchDrum_38 Velocity_87 Duration_0.2.8 TimeShift_0.2.8 PitchDrum_38 Velocity_79 Duration_0.2.8 PitchDrum_42 Velocity_103 Duration_0.2.8 PitchDrum_51 Velocity_119 Duration_0.2.8 TimeShift_0.6.8 PitchDrum_51 Velocity_63 Duration_0.2.8 TimeShift_0.2.8 PitchDrum_38 Velocity_79 Duration_0.2.8 PitchDrum_51 Velocity_103 Duration_0.2.8 TimeShift_0.6.8 PitchDrum_51 Velocity_87 Duration_0.2.8 TimeShift_0.2.8 PitchDrum_38 Velocity_79 Duration_0.4.8 PitchDrum_42 Velocity_103 Duration_0.2.8 PitchDrum_51 Velocity_111 Duration_0.2.8 TimeShift_0.6.8 PitchDrum_51 Velocity_55 Duration_0.2.8 Bar_End Bar_Start PitchDrum_35 Velocity_79 Duration_0.2.8 PitchDrum_38 Velocity_79 Duration_0.2.8 PitchDrum_51 Velocity_103 Duration_0.2.8 TimeShift_1.0.8 PitchDrum_38 Velocity_79 Duration_0.2.8 PitchDrum_42 Velocity_103 Duration_0.2.8 PitchDrum_51 Velocity_119 Duration_0.2.8 TimeShift_0.6.8 PitchDrum_51 Velocity_95 Duration_0.2.8 TimeShift_0.2.8 PitchDrum_38 Velocity_79 Duration_0.4.8 PitchDrum_51 Velocity_95 Duration_0.2.8 TimeShift_0.6.8 PitchDrum_38 Velocity_79 Duration_0.2.8 TimeShift_0.2.8 PitchDrum_42 Velocity_103 Duration_0.2.8 PitchDrum_45 Velocity_63 Duration_0.2.8 PitchDrum_51 Velocity_119 Duration_0.2.8 TimeShift_0.6.8 PitchDrum_35 Velocity_71 Duration_0.2.8 PitchDrum_45 Velocity_63 Duration_0.2.8 PitchDrum_51 Velocity_79 Duration_0.2.8 Bar_End Bar_Start PitchDrum_51 Velocity_95 Duration_0.2.8 TimeShift_0.6.8 PitchDrum_38 Velocity_79 Duration_0.2.8 TimeShift_0.2.8 PitchDrum_38 Velocity_79 Duration_0.2.8 PitchDrum_42 Velocity_103 Duration_0.2.8 PitchDrum_51 Velocity_111 Duration_0.2.8 TimeShift_0.6.8 PitchDrum_51 Velocity_55 Duration_0.2.8 TimeShift_0.2.8 PitchDrum_38 Velocity_87 Duration_0.2.8 PitchDrum_51 Velocity_95 Duration_0.2.8 TimeShift_1.0.8 PitchDrum_38 Velocity_79 Duration_0.2.8 PitchDrum_42 Velocity_103 Duration_0.2.8 PitchDrum_51 Velocity_119 Duration_0.2.8 TimeShift_0.6.8 PitchDrum_51 Velocity_55 Duration_0.2.8 Bar_End Bar_Start PitchDrum_35 Velocity_79 Duration_0.2.8 PitchDrum_38 Velocity_79 Duration_0.2.8 PitchDrum_51 Velocity_103 Duration_0.2.8 TimeShift_1.0.8 PitchDrum_38 Velocity_87 Duration_0.2.8 PitchDrum_42 Velocity_95 Duration_0.2.8 PitchDrum_51 Velocity_119 Duration_0.2.8 TimeShift_0.6.8 PitchDrum_51 Velocity_95 Duration_0.2.8 TimeShift_0.2.8 PitchDrum_38 Velocity_87 Duration_0.4.8 PitchDrum_51 Velocity_103 Duration_0.2.8 TimeShift_0.6.8 PitchDrum_38 Velocity_87 Duration_0.2.8 PitchDrum_51 Velocity_87 Duration_0.2.8 TimeShift_0.2.8 PitchDrum_42 Velocity_103 Duration_0.2.8 PitchDrum_51 Velocity_119 Duration_0.2.8 TimeShift_0.2.8 PitchDrum_38 Velocity_71 Duration_0.2.8 TimeShift_0.4.8 PitchDrum_35 Velocity_71 Duration_0.2.8 PitchDrum_51 Velocity_79 Duration_0.2.8 Bar_End Track_End Track_Start Program_32 NoteDensity_2 Bar_Start Pitch_43 Velocity_79 Duration_0.6.8 TimeShift_1.0.8 PitchIntervalTime_0 Velocity_79 Duration_0.6.8 TimeShift_1.0.8 PitchIntervalTime_-7 Velocity_87 Duration_0.2.8 TimeShift_0.6.8 PitchIntervalTime_15 Velocity_79 Duration_0.2.8 TimeShift_0.2.8 PitchIntervalTime_1 Velocity_79 Duration_0.6.8 PitchIntervalChord_6 Velocity_79 Duration_0.6.8 Bar_End Bar_Start PitchIntervalTime_-15 Velocity_79 Duration_1.0.8 TimeShift_1.0.8 PitchIntervalTime_0 Velocity_79 Duration_0.6.8 TimeShift_1.0.8 PitchIntervalTime_5 Velocity_79 Duration_1.0.8 TimeShift_1.0.8 PitchIntervalTime_-5 Velocity_87 Duration_0.4.8 TimeShift_0.6.8 PitchIntervalTime_5 Velocity_79 Duration_0.2.8 Bar_End Bar_Start PitchIntervalTime_0 Velocity_87 Duration_1.0.8 TimeShift_1.0.8 PitchIntervalTime_-5 Velocity_79 Duration_0.4.8 TimeShift_0.6.8 PitchIntervalTime_5 Velocity_87 Duration_0.2.8 TimeShift_0.2.8 PitchIntervalTime_-7 Velocity_79 Duration_0.2.8 TimeShift_0.6.8 PitchIntervalTime_15 Velocity_79 Duration_0.2.8 TimeShift_0.2.8 PitchIntervalTime_1 Velocity_79 Duration_0.6.8 PitchIntervalChord_6 Velocity_87 Duration_0.6.8 Bar_End Bar_Start PitchIntervalTime_-15 Velocity_87 Duration_0.6.8 TimeShift_1.0.8 PitchIntervalTime_0 Velocity_79 Duration_0.6.8 TimeShift_1.0.8 PitchIntervalTime_5 Velocity_79 Duration_0.6.8 TimeShift_1.0.8 PitchIntervalTime_0 Velocity_79 Duration_0.6.8 Bar_End Track_End Track_Start Program_0 NoteDensity_2 Bar_Start Pitch_58 Velocity_79 Duration_0.6.8 PitchIntervalChord_12 Velocity_63 Duration_0.6.8 PitchIntervalChord_9 Velocity_71 Duration_0.6.8 PitchIntervalChord_3 Velocity_79 Duration_0.6.8 PitchIntervalChord_4 Velocity_71 Duration_0.6.8 TimeShift_0.2.8 PitchIntervalTime_9 Velocity_79 Duration_0.4.8 TimeShift_2.4.8 Pitch_58 Velocity_95 Duration_0.2.8 PitchIntervalChord_4 Velocity_87 Duration_0.2.8 PitchIntervalChord_2 Velocity_87 Duration_0.2.8 PitchIntervalChord_5 Velocity_87 Duration_0.2.8 Bar_End Bar_Start Pitch_64 Velocity_79 Duration_0.6.8 PitchIntervalChord_4 Velocity_63 Duration_0.6.8 PitchIntervalChord_8 Velocity_71 Duration_0.6.8 PitchIntervalChord_4 Velocity_71 Duration_0.6.8 PitchIntervalChord_5 Velocity_79 Duration_0.6.8 TimeShift_0.2.8 PitchIntervalTime_-8 Velocity_71 Duration_0.4.8 TimeShift_1.6.8 Pitch_64 Velocity_79 Duration_0.6.8 PitchIntervalChord_2 Velocity_63 Duration_0.6.8 PitchIntervalChord_10 Velocity_71 Duration_0.6.8 PitchIntervalChord_2 Velocity_71 Duration_0.6.8 PitchIntervalChord_9 Velocity_71 Duration_0.6.8 TimeShift_0.2.8 PitchIntervalTime_-6 Velocity_71 Duration_0.4.8 Bar_End Bar_Start Pitch_54 Velocity_63 Duration_1.6.8 PitchIntervalChord_7 Velocity_55 Duration_2.0.8 PitchIntervalChord_5 Velocity_55 Duration_1.6.8 PitchIntervalChord_3 Velocity_71 Duration_1.6.8 PitchIntervalChord_9 Velocity_71 Duration_1.6.8 TimeShift_2.0.8 Pitch_51 Velocity_63 Duration_1.6.8 PitchIntervalChord_6 Velocity_47 Duration_1.6.8 PitchIntervalChord_6 Velocity_55 Duration_1.6.8 PitchIntervalChord_3 Velocity_71 Duration_1.6.8 PitchIntervalChord_5 Velocity_71 Duration_1.6.8 Bar_End Bar_Start Pitch_51 Velocity_63 Duration_1.6.8 PitchIntervalChord_9 Velocity_55 Duration_1.6.8 PitchIntervalChord_3 Velocity_55 Duration_1.6.8 PitchIntervalChord_4 Velocity_71 Duration_1.6.8 PitchIntervalChord_8 Velocity_71 Duration_1.6.8 TimeShift_2.0.8 Pitch_63 Velocity_79 Duration_0.6.8 PitchIntervalChord_4 Velocity_71 Duration_0.6.8 PitchIntervalChord_8 Velocity_63 Duration_0.6.8 PitchIntervalChord_4 Velocity_79 Duration_0.6.8 PitchIntervalChord_5 Velocity_79 Duration_0.6.8 TimeShift_0.2.8 PitchIntervalTime_-6 Velocity_71 Duration_0.4.8 Bar_End Track_End Track_Start Program_56 NoteDensity_4 Bar_Start TimeShift_0.6.8 Pitch_72 Velocity_79 Duration_0.2.8 PitchIntervalChord_5 Velocity_79 Duration_0.2.8 PitchIntervalChord_4 Velocity_79 Duration_0.2.8 PitchIntervalChord_3 Velocity_95 Duration_0.2.8 TimeShift_0.2.8 PitchIntervalTime_-2 Velocity_79 Duration_0.2.8 PitchIntervalChord_4 Velocity_79 Duration_0.2.8 PitchIntervalChord_5 Velocity_79 Duration_0.2.8 PitchIntervalChord_3 Velocity_95 Duration_0.2.8 TimeShift_1.0.8 PitchIntervalTime_-1 Velocity_87 Duration_0.2.8 PitchIntervalChord_8 Velocity_87 Duration_0.2.8 PitchIntervalChord_4 Velocity_95 Duration_0.2.8 PitchIntervalChord_-7 Velocity_79 Duration_0.4.8 TimeShift_1.0.8 PitchIntervalTime_-2 Velocity_79 Duration_0.2.8 PitchIntervalChord_2 Velocity_79 Duration_0.2.8 PitchIntervalChord_5 Velocity_79 Duration_0.2.8 PitchIntervalChord_5 Velocity_95 Duration_0.2.8 Bar_End Bar_Start PitchIntervalTime_-1 Velocity_87 Duration_0.2.8 PitchIntervalChord_12 Velocity_87 Duration_0.2.8 PitchIntervalChord_-7 Velocity_79 Duration_0.4.8 PitchIntervalChord_4 Velocity_79 Duration_0.4.8 TimeShift_1.0.8 PitchIntervalTime_-2 Velocity_87 Duration_0.2.8 PitchIntervalChord_4 Velocity_79 Duration_0.2.8 PitchIntervalChord_8 Velocity_95 Duration_0.2.8 PitchIntervalChord_-3 Velocity_87 Duration_0.4.8 TimeShift_1.0.8 PitchIntervalTime_-1 Velocity_79 Duration_0.4.8 PitchIntervalChord_5 Velocity_79 Duration_0.4.8 PitchIntervalChord_3 Velocity_79 Duration_0.4.8 PitchIntervalChord_4 Velocity_95 Duration_0.4.8 TimeShift_0.6.8 PitchIntervalTime_-2 Velocity_79 Duration_0.2.8 PitchIntervalChord_2 Velocity_79 Duration_0.2.8 PitchIntervalChord_5 Velocity_87 Duration_0.2.8 PitchIntervalChord_5 Velocity_95 Duration_0.2.8 Bar_End Bar_Start TimeShift_0.6.8 Pitch_71 Velocity_79 Duration_0.2.8 PitchIntervalChord_5 Velocity_87 Duration_0.2.8 PitchIntervalChord_4 Velocity_79 Duration_0.2.8 PitchIntervalChord_3 Velocity_95 Duration_0.2.8 TimeShift_0.2.8 PitchIntervalTime_-2 Velocity_79 Duration_0.2.8 PitchIntervalChord_4 Velocity_79 Duration_0.2.8 PitchIntervalChord_5 Velocity_79 Duration_0.2.8 PitchIntervalChord_3 Velocity_95 Duration_0.2.8 TimeShift_1.0.8 PitchIntervalTime_-1 Velocity_79 Duration_0.2.8 PitchIntervalChord_5 Velocity_79 Duration_0.2.8 PitchIntervalChord_3 Velocity_87 Duration_0.2.8 PitchIntervalChord_4 Velocity_95 Duration_0.2.8 TimeShift_1.0.8 PitchIntervalTime_0 Velocity_79 Duration_0.2.8 PitchIntervalChord_10 Velocity_87 Duration_0.2.8 PitchIntervalChord_-12 Velocity_79 Duration_0.4.8 PitchIntervalChord_7 Velocity_79 Duration_0.4.8 Bar_End Bar_Start PitchIntervalTime_-3 Velocity_79 Duration_0.2.8 PitchIntervalChord_5 Velocity_79 Duration_0.2.8 PitchIntervalChord_4 Velocity_79 Duration_0.4.8 PitchIntervalChord_3 Velocity_95 Duration_0.4.8 TimeShift_1.0.8 PitchIntervalTime_-2 Velocity_79 Duration_0.2.8 PitchIntervalChord_4 Velocity_79 Duration_0.2.8 PitchIntervalChord_5 Velocity_87 Duration_0.2.8 PitchIntervalChord_3 Velocity_95 Duration_0.4.8 TimeShift_1.0.8 PitchIntervalTime_-1 Velocity_79 Duration_0.4.8 PitchIntervalChord_5 Velocity_79 Duration_0.4.8 PitchIntervalChord_3 Velocity_79 Duration_0.4.8 PitchIntervalChord_4 Velocity_95 Duration_0.4.8 TimeShift_0.6.8 PitchIntervalTime_-2 Velocity_79 Duration_0.2.8 PitchIntervalChord_2 Velocity_87 Duration_0.2.8 PitchIntervalChord_5 Velocity_79 Duration_0.2.8 PitchIntervalChord_5 Velocity_95 Duration_0.2.8 Bar_End Track_End Track_Start Program_57 NoteDensity_4 Bar_Start TimeShift_0.6.8 Pitch_62 Velocity_79 Duration_0.2.8 PitchIntervalChord_3 Velocity_79 Duration_0.2.8 PitchIntervalChord_5 Velocity_79 Duration_0.2.8 PitchIntervalChord_-15 Velocity_79 Duration_0.4.8 TimeShift_0.2.8 PitchIntervalTime_-2 Velocity_87 Duration_0.2.8 PitchIntervalChord_2 Velocity_79 Duration_0.2.8 PitchIntervalChord_3 Velocity_79 Duration_0.2.8 TimeShift_1.0.8 PitchIntervalTime_-12 Velocity_87 Duration_0.2.8 PitchIntervalChord_10 Velocity_79 Duration_0.2.8 PitchIntervalChord_4 Velocity_79 Duration_0.2.8 PitchIntervalChord_3 Velocity_79 Duration_0.2.8 TimeShift_1.0.8 PitchIntervalTime_0 Velocity_87 Duration_0.2.8 PitchIntervalChord_14 Velocity_79 Duration_0.2.8 PitchIntervalChord_2 Velocity_87 Duration_0.2.8 PitchIntervalChord_-6 Velocity_79 Duration_0.4.8 Bar_End Bar_Start PitchIntervalTime_8 Velocity_79 Duration_0.2.8 PitchIntervalChord_3 Velocity_79 Duration_0.2.8 PitchIntervalChord_5 Velocity_79 Duration_0.2.8 PitchIntervalChord_-15 Velocity_87 Duration_0.4.8 TimeShift_1.0.8 PitchIntervalTime_-2 Velocity_79 Duration_0.2.8 PitchIntervalChord_2 Velocity_79 Duration_0.2.8 PitchIntervalChord_3 Velocity_87 Duration_0.2.8 PitchIntervalChord_-10 Velocity_79 Duration_0.4.8 TimeShift_1.0.8 PitchIntervalTime_-12 Velocity_79 Duration_0.4.8 PitchIntervalChord_10 Velocity_79 Duration_0.4.8 PitchIntervalChord_4 Velocity_79 Duration_0.4.8 PitchIntervalChord_3 Velocity_79 Duration_0.4.8 TimeShift_0.6.8 PitchIntervalTime_0 Velocity_79 Duration_0.2.8 PitchIntervalChord_10 Velocity_87 Duration_0.2.8 PitchIntervalChord_4 Velocity_79 Duration_0.2.8 PitchIntervalChord_2 Velocity_79 Duration_0.2.8 Bar_End Bar_Start TimeShift_0.6.8 Pitch_61 Velocity_79 Duration_0.2.8 PitchIntervalChord_3 Velocity_79 Duration_0.2.8 PitchIntervalChord_7 Velocity_79 Duration_0.2.8 Pitch_54 Velocity_79 Duration_0.4.8 TimeShift_0.2.8 PitchIntervalTime_5 Velocity_79 Duration_0.2.8 PitchIntervalChord_2 Velocity_87 Duration_0.2.8 PitchIntervalChord_3 Velocity_79 Duration_0.2.8 TimeShift_1.0.8 PitchIntervalTime_5 Velocity_79 Duration_0.2.8 Pitch_47 Velocity_79 Duration_0.4.8 PitchIntervalChord_10 Velocity_79 Duration_0.4.8 PitchIntervalChord_4 Velocity_79 Duration_0.4.8 TimeShift_1.0.8 PitchIntervalTime_10 Velocity_79 Duration_0.2.8 PitchIntervalChord_4 Velocity_87 Duration_0.2.8 PitchIntervalChord_2 Velocity_79 Duration_0.2.8 PitchIntervalChord_-16 Velocity_79 Duration_0.4.8 Bar_End Bar_Start PitchIntervalTime_-2 Velocity_79 Duration_0.2.8 PitchIntervalChord_3 Velocity_87 Duration_0.2.8 PitchIntervalChord_5 Velocity_79 Duration_0.2.8 PitchIntervalChord_-15 Velocity_79 Duration_0.4.8 TimeShift_1.0.8 PitchIntervalTime_-2 Velocity_79 Duration_0.2.8 PitchIntervalChord_2 Velocity_79 Duration_0.2.8 PitchIntervalChord_-7 Velocity_87 Duration_0.4.8 PitchIntervalChord_10 Velocity_79 Duration_0.4.8 TimeShift_1.0.8 PitchIntervalTime_-12 Velocity_87 Duration_0.4.8 PitchIntervalChord_10 Velocity_87 Duration_0.4.8 PitchIntervalChord_4 Velocity_79 Duration_0.4.8 PitchIntervalChord_3 Velocity_79 Duration_0.4.8 TimeShift_0.6.8 PitchIntervalTime_0 Velocity_87 Duration_0.2.8 PitchIntervalChord_10 Velocity_79 Duration_0.2.8 PitchIntervalChord_4 Velocity_87 Duration_0.2.8 PitchIntervalChord_2 Velocity_79 Duration_0.2.8 Bar_End Track_End'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_midi = Score(jazz_midi_paths_train[0])\n",
    "t = texter(sample_midi).tokens\n",
    "t = ' '.join(t)\n",
    "t = tokenizer.encode(t)\n",
    "tokenizer.decode(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Dataset classes to be used with PyTorch when training a model.\"\"\"\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "from abc import ABC\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "from typing import TYPE_CHECKING, Any\n",
    "\n",
    "from symusic import Score\n",
    "from torch import LongTensor, randint\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "from miditok.constants import MIDI_FILES_EXTENSIONS\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from collections.abc import Callable, Mapping, Sequence\n",
    "\n",
    "    from miditok import MIDITokenizer\n",
    "\n",
    "\n",
    "def split_seq_in_subsequences(\n",
    "    seq: Sequence[any], min_seq_len: int, max_seq_len: int\n",
    ") -> list[Sequence[Any]]:\n",
    "    r\"\"\"\n",
    "    Split a sequence of tokens into subsequences.\n",
    "\n",
    "    The subsequences will have lengths comprised between ``min_seq_len`` and\n",
    "    ``max_seq_len``: ``min_seq_len <= len(sub_seq) <= max_seq_len``.\n",
    "\n",
    "    :param seq: sequence to split.\n",
    "    :param min_seq_len: minimum sequence length.\n",
    "    :param max_seq_len: maximum sequence length.\n",
    "    :return: list of subsequences.\n",
    "    \"\"\"\n",
    "    sub_seq = []\n",
    "    i = 0\n",
    "    while i < len(seq):\n",
    "        if i >= len(seq) - min_seq_len:\n",
    "            break  # last sample is too short\n",
    "        sub_seq.append(LongTensor(seq[i : i + max_seq_len]))\n",
    "        i += len(sub_seq[-1])  # could be replaced with max_seq_len\n",
    "\n",
    "    return sub_seq\n",
    "\n",
    "\n",
    "def split_dataset_to_subsequences(\n",
    "    files_paths: Sequence[Path | str],\n",
    "    out_dir: Path | str,\n",
    "    min_seq_len: int,\n",
    "    max_seq_len: int,\n",
    "    one_token_stream: bool = True,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Split a dataset of tokens files into subsequences.\n",
    "\n",
    "    This method is particularly useful if you plan to use a\n",
    "    :class:`miditok.pytorch_data.DatasetJsonIO`, as it would split token sequences\n",
    "    into subsequences with the desired lengths before loading them for training.\n",
    "\n",
    "    :param files_paths: list of files of tokens to split.\n",
    "    :param out_dir: output directory to save the subsequences.\n",
    "    :param min_seq_len: minimum sequence length.\n",
    "    :param max_seq_len: maximum sequence length.\n",
    "    :param one_token_stream: give False if the token files contains multiple tracks,\n",
    "        i.e. the first dimension of the value of the \"ids\" entry corresponds to several\n",
    "        tracks. Otherwise, leave False. (default: True)\n",
    "    \"\"\"\n",
    "    out_dir = Path(out_dir)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for file_path in files_paths:\n",
    "        with Path(file_path).open() as json_file:\n",
    "            tokens = json.load(json_file)\n",
    "\n",
    "        # Split sequence(s)\n",
    "        if one_token_stream:\n",
    "            subseqs = split_seq_in_subsequences(tokens[\"ids\"], min_seq_len, max_seq_len)\n",
    "        else:\n",
    "            subseqs = []\n",
    "            for track_seq in tokens[\"ids\"]:\n",
    "                subseqs += split_seq_in_subsequences(\n",
    "                    track_seq, min_seq_len, max_seq_len\n",
    "                )\n",
    "\n",
    "        # Save subsequences\n",
    "        for i, subseq in enumerate(subseqs):\n",
    "            path = out_dir / f\"{file_path.name}_{i}.json\"\n",
    "            with path.open(\"w\") as outfile:\n",
    "                new_tok = deepcopy(tokens)\n",
    "                new_tok[\"ids\"] = subseq\n",
    "                json.dump(tokens, outfile)\n",
    "\n",
    "\n",
    "class _DatasetABC(Dataset, ABC):\n",
    "    r\"\"\"\n",
    "    Abstract ``Dataset`` class.\n",
    "\n",
    "    It holds samples (and optionally labels) and implements the basic magic methods.\n",
    "\n",
    "    :param samples: sequence of input samples. It can directly be data, or a paths to\n",
    "        files to be loaded.\n",
    "    :param labels: sequence of labels associated with the samples. (default: ``None``)\n",
    "    :param sample_key_name: name of the dictionary key containing the sample data when\n",
    "        iterating the dataset. (default: ``\"input_ids\"``)\n",
    "    :param labels_key_name: name of the dictionary key containing the labels data when\n",
    "        iterating the dataset. (default: ``\"labels\"``)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        samples: Sequence[Any] | None = None,\n",
    "        labels: Sequence[Any] | None = None,\n",
    "        sample_key_name: str = \"input_ids\",\n",
    "        labels_key_name: str = \"labels\",\n",
    "    ) -> None:\n",
    "        if samples is not None and labels is not None and len(samples) != len(labels):\n",
    "            msg = \"The number of samples must be the same as the number of labels\"\n",
    "            raise ValueError(msg)\n",
    "        self.samples = samples if samples is not None else []\n",
    "        self.labels = labels\n",
    "        self.sample_key_name = sample_key_name\n",
    "        self.labels_key_name = labels_key_name\n",
    "        self.__iter_count = 0\n",
    "\n",
    "    def reduce_num_samples(self, num_samples: int) -> None:\n",
    "        r\"\"\"\n",
    "        Reduce the size of the dataset, by keeping `num_samples` samples.\n",
    "\n",
    "        :param num_samples: number of samples to keep. They will be randomly picked.\n",
    "        \"\"\"\n",
    "        idx = randint(0, len(self), (num_samples,))\n",
    "        self.samples = [self.samples[id_] for id_ in idx.tolist()]\n",
    "        if self.labels is not None:\n",
    "            self.labels = [self.labels[id_] for id_ in idx.tolist()]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Mapping[str, Any]:\n",
    "        item = {self.sample_key_name: self.samples[idx]}\n",
    "        if self.labels is not None:\n",
    "            item[self.labels_key_name] = self.labels[idx]\n",
    "\n",
    "        return item\n",
    "\n",
    "    def __iter__(self) -> _DatasetABC:\n",
    "        return self\n",
    "\n",
    "    def __next__(self) -> Mapping[str, Any]:\n",
    "        if self.__iter_count >= len(self):\n",
    "            self.__iter_count = 0\n",
    "            raise StopIteration\n",
    "\n",
    "        self.__iter_count += 1\n",
    "        return self[self.__iter_count - 1]\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return self.__str__()\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return \"No data loaded\" if len(self) == 0 else f\"{len(self.samples)} samples\"\n",
    "\n",
    "\n",
    "class GenreDatasetTok(_DatasetABC):\n",
    "    r\"\"\"\n",
    "    Basic ``Dataset`` loading and tokenizing MIDIs or JSON token files.\n",
    "\n",
    "    The token ids will be stored in RAM. It outputs token sequences that can be used to\n",
    "    train models.\n",
    "\n",
    "    The tokens sequences being loaded will then be split into subsequences, of length\n",
    "    comprise between ``min_seq_len`` and ``max_seq_len``.\n",
    "    For example, with ``min_seq_len = 50`` and ``max_seq_len = 100``:\n",
    "    * a sequence of 650 tokens will be split into 6 subsequences of 100 tokens plus one\n",
    "    subsequence of 50 tokens;\n",
    "    * a sequence of 620 tokens will be split into 6 subsequences of 100 tokens, the\n",
    "    last 20 tokens will be discarded;\n",
    "    * a sequence of 670 tokens will be split into 6 subsequences of 100 tokens plus one\n",
    "    subsequence of 50 tokens, and the last 20 tokens will be discarded.\n",
    "\n",
    "    This `Dataset` class is well suited if you have enough RAM to store all the data,\n",
    "    as it does not require you to prior split the dataset into subsequences of the\n",
    "    length you desire. Note that if you directly load MIDI files, the loading can take\n",
    "    some time as they will need to be tokenized. You might want to tokenize them before\n",
    "    once with the ``tokenizer.tokenize_midi_dataset()`` method.\n",
    "\n",
    "    Additionally, you can use the `func_to_get_labels` argument to provide a method\n",
    "    allowing to use labels (one label per file).\n",
    "\n",
    "    :param files_paths: list of paths to files to load.\n",
    "    :param min_seq_len: minimum sequence length (in num of tokens)\n",
    "    :param max_seq_len: maximum sequence length (in num of tokens)\n",
    "    :param tokenizer: tokenizer object, to use to load MIDIs instead of tokens.\n",
    "        (default: ``None``)\n",
    "    :param one_token_stream: give False if the token files contains multiple tracks,\n",
    "        i.e. the first dimension of the value of the \"ids\" entry corresponds to\n",
    "        several tracks. Otherwise, leave False. (default: ``True``)\n",
    "    :param func_to_get_labels: a function to retrieve the label of a file. The method\n",
    "        must take two positional arguments: the first is either a MidiFile or the\n",
    "        tokens loaded from the json file, the second is the path to the file just\n",
    "        loaded. The method must return an integer which correspond to the label id\n",
    "        (and not the absolute value, e.g. if you are classifying 10 musicians, return\n",
    "        the id from 0 to 9 included corresponding to the musician). (default: ``None``)\n",
    "    :param sample_key_name: name of the dictionary key containing the sample data when\n",
    "        iterating the dataset. (default: ``\"input_ids\"``)\n",
    "    :param labels_key_name: name of the dictionary key containing the labels data when\n",
    "        iterating the dataset. (default: ``\"labels\"``)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        genre_token_ids: str,\n",
    "        files_paths: Sequence[Path],\n",
    "        min_seq_len: int,\n",
    "        max_seq_len: int,\n",
    "        texter: MIDITokenizer | None,\n",
    "        tokenizer: None,\n",
    "        one_token_stream: bool = True,\n",
    "        func_to_get_labels: Callable[[Score | Sequence, Path], int] | None = None,\n",
    "        sample_key_name: str = \"input_ids\",\n",
    "        labels_key_name: str = \"labels\",\n",
    "    ) -> None:\n",
    "        labels = None if func_to_get_labels is None else []\n",
    "        samples = []\n",
    "        if tokenizer is not None:\n",
    "            one_token_stream = True\n",
    "\n",
    "        for file_path in tqdm(\n",
    "            files_paths,\n",
    "            desc=f\"Loading data: {files_paths[0].parent}\",\n",
    "            miniters=int(len(files_paths) / 20),\n",
    "            maxinterval=480,\n",
    "        ):\n",
    "            label = None\n",
    "            # Loading a MIDI file\n",
    "            if file_path.suffix in MIDI_FILES_EXTENSIONS:\n",
    "                midi = Score(file_path)\n",
    "                if func_to_get_labels is not None:\n",
    "                    label = func_to_get_labels(midi, file_path)\n",
    "                text_midi = texter(midi)\n",
    "                if one_token_stream:\n",
    "                    text_midi = \" \".join(text_midi.tokens)\n",
    "                    tokens_ids = tokenizer.encode(text_midi)\n",
    "                else:\n",
    "                    text_midi = [\" \".join(seq.tokens) for seq in text_midi]\n",
    "                    text_midi = [tokenizer.encode(seq) for seq in text_midi]\n",
    "            # Loading json tokens\n",
    "            # else:\n",
    "            #     with file_path.open() as json_file:\n",
    "            #         tokens = json.load(json_file)\n",
    "            #     if func_to_get_labels is not None:\n",
    "            #         label = func_to_get_labels(tokens, file_path)\n",
    "            #     tokens_ids = tokens[\"ids\"]\n",
    "                \n",
    "            # Concat genre token\n",
    "            if one_token_stream:\n",
    "                tokens_ids = genre_token_ids + tokens_ids\n",
    "            else:\n",
    "                tokens_ids = [genre_token_ids + seq_ids for seq_ids in tokens_ids]\n",
    "\n",
    "            # Cut tokens in samples of appropriate length\n",
    "            if one_token_stream:\n",
    "                tokens_ids = [tokens_ids]\n",
    "            for seq in tokens_ids:\n",
    "                subseqs = split_seq_in_subsequences(seq, min_seq_len, max_seq_len)\n",
    "                samples += subseqs\n",
    "                if label is not None:\n",
    "                    labels += [label] * len(subseqs)\n",
    "\n",
    "        if labels is not None:\n",
    "            labels = LongTensor(labels)\n",
    "        super().__init__(\n",
    "            samples,\n",
    "            labels,\n",
    "            sample_key_name=sample_key_name,\n",
    "            labels_key_name=labels_key_name,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: jazz-chunked/195_LittlePixieG_cleaned: 100%|██████████| 27/27 [00:00<00:00, 84.29it/s]\n",
      "Loading data: jazz-chunked/195_LittlePixieG_cleaned: 100%|██████████| 3/3 [00:00<00:00, 41.48it/s]\n",
      "Loading data: ../ym-test/chunks: 100%|██████████| 19/19 [00:00<00:00, 108.90it/s]\n",
      "Loading data: ../ym-test/chunks: 100%|██████████| 2/2 [00:00<00:00, 102.24it/s]\n"
     ]
    }
   ],
   "source": [
    "jazz_dataset_train = GenreDatasetTok(\n",
    "    genre_token_ids=tokenizer.encode(\"Genre_Jazz\"),\n",
    "    files_paths=jazz_midi_paths_train,\n",
    "    min_seq_len=50,\n",
    "    max_seq_len=1022,\n",
    "    texter=texter,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "jazz_dataset_valid = GenreDatasetTok(\n",
    "    genre_token_ids=tokenizer.encode(\"Genre_Jazz\"),\n",
    "    files_paths=jazz_midi_paths_valid,\n",
    "    min_seq_len=50,\n",
    "    max_seq_len=1022,\n",
    "    texter=texter,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "ym_dataset_train = GenreDatasetTok(\n",
    "    genre_token_ids=tokenizer.encode(\"Genre_Ym\"),\n",
    "    files_paths=ym_midi_paths_train,\n",
    "    min_seq_len=50,\n",
    "    max_seq_len=1022,\n",
    "    texter=texter,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "ym_dataset_valid = GenreDatasetTok(\n",
    "    genre_token_ids=tokenizer.encode(\"Genre_Ym\"),\n",
    "    files_paths=ym_midi_paths_valid,\n",
    "    min_seq_len=50,\n",
    "    max_seq_len=1022,\n",
    "    texter=texter,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(13746), tensor(13746))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jazz_dataset_train[0]['input_ids'][0], ym_dataset_train[0]['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat datasets\n",
    "dataset_train = jazz_dataset_train + ym_dataset_train\n",
    "dataset_valid = jazz_dataset_valid + ym_dataset_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'GPT2TokenizerFast' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m collator \u001b[38;5;241m=\u001b[39m DataCollator(\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mtokenizer\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPAD_None\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m, tokenizer[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBOS_None\u001b[39m\u001b[38;5;124m\"\u001b[39m], tokenizer[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEOS_None\u001b[39m\u001b[38;5;124m\"\u001b[39m], copy_inputs_as_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      3\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: 'GPT2TokenizerFast' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "\n",
    "# collator = DataCollator(\n",
    "#     tokenizer[\"PAD_None\"], tokenizer[\"BOS_None\"], tokenizer[\"EOS_None\"], copy_inputs_as_labels=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_loader_train = DataLoader(dataset=dataset_train)\n",
    "data_loader_valid = DataLoader(dataset=dataset_valid)\n",
    "train_tokenized_songs = []\n",
    "valid_tokenized_songs = []\n",
    "for batch in data_loader_train:\n",
    "    train_tokenized_songs.append(batch)\n",
    "for batch in data_loader_valid:\n",
    "    valid_tokenized_songs.append(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make custom dataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MidiDataset(Dataset):\n",
    "    def __init__(self, tokenized_songs, max_length=510):  # max_length를 512로 하면 앞, 뒤에 BOS, EOS 토큰이 또 붙어서 길이 514 되고 에러가 나서 일단 510로 함. 디버깅 필요!!\n",
    "        self.tokenized_songs = tokenized_songs\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tokenized_songs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # item = {key: val.clone().detach() for key, val in self.tokenized_songs[idx].items()}\n",
    "        item = {'input_ids': self.tokenized_songs[idx]['input_ids'][:, :self.max_length].clone().detach().squeeze(),}\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MidiDataset(train_tokenized_songs)\n",
    "eval_dataset = MidiDataset(valid_tokenized_songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([510]), torch.Size([510]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]['input_ids'].shape, eval_dataset[0]['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test our data_collator\n",
    "# out = collator([train_dataset[i] for i in range(5)])\n",
    "\n",
    "# for key in out:\n",
    "#     print(f\"{key} shape: {out[key].shape}\")\n",
    "\n",
    "# print(f\"out {out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# first create a custom trainer to log prediction distribution\n",
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def evaluation_loop(\n",
    "        self,\n",
    "        dataloader,\n",
    "        description,\n",
    "        prediction_loss_only=None,\n",
    "        ignore_keys=None,\n",
    "        metric_key_prefix=\"eval\",\n",
    "    ):\n",
    "        # call super class method to get the eval outputs\n",
    "        eval_output = super().evaluation_loop(\n",
    "            dataloader,\n",
    "            description,\n",
    "            prediction_loss_only,\n",
    "            ignore_keys,\n",
    "            metric_key_prefix,\n",
    "        )\n",
    "\n",
    "        return eval_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, GPT2LMHeadModel\n",
    "\n",
    "context_length = 1024 # context length는 자유롭게 바꿔보며 실험해봐도 좋을 듯 합니다.\n",
    "\n",
    "# Change this based on size of the data\n",
    "n_layer=6\n",
    "n_head=4\n",
    "n_emb=1024\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    vocab_size=len(tokenizer),\n",
    "    n_positions=context_length,\n",
    "    n_layer=n_layer,\n",
    "    n_head=n_head,\n",
    "    pad_token_id=tokenizer[\"PAD_None\"],\n",
    "    bos_token_id=tokenizer[\"BOS_None\"],\n",
    "    eos_token_id=tokenizer[\"EOS_None\"],\n",
    "    n_embd=n_emb\n",
    ")\n",
    "\n",
    "model = GPT2LMHeadModel(config)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the args for out trainer\n",
    "from argparse import Namespace\n",
    "\n",
    "# Get the output directory with timestamp.\n",
    "output_path = \"models\"\n",
    "steps = 100\n",
    "# Commented parameters correspond to the small model\n",
    "config = {\"output_dir\": output_path,\n",
    "          \"num_train_epochs\": 30, # 학습 epoch 자유롭게 변경. 저는 30 epoch 걸어놓고 early stopping 했습니다.\n",
    "          \"per_device_train_batch_size\": 32,\n",
    "          \"per_device_eval_batch_size\": 16,\n",
    "          \"evaluation_strategy\": \"steps\",\n",
    "          \"save_strategy\": \"steps\",\n",
    "          \"eval_steps\": steps,\n",
    "          \"logging_steps\":steps,\n",
    "          \"logging_first_step\": True,\n",
    "          \"save_total_limit\": 5,\n",
    "          \"save_steps\": steps,\n",
    "          \"lr_scheduler_type\": \"cosine\",\n",
    "          \"learning_rate\":5e-4,\n",
    "          \"warmup_ratio\": 0.01,\n",
    "          \"weight_decay\": 0.01,\n",
    "          \"seed\": 1,\n",
    "          \"load_best_model_at_end\": True,\n",
    "          # \"metric_for_best_model\": \"eval_loss\" # best model 기준 바꾸고 싶을 경우 이 부분 변경 (default가 eval_loss임)\n",
    "        #   \"report_to\": \"wandb\"\n",
    "          }\n",
    "\n",
    "args = Namespace(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import set_seed\n",
    "set_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "# mps device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = GPT2LMHeadModel(config)\n",
    "model\n",
    "model.to(device)\n",
    "\n",
    "train_args = TrainingArguments(**config)\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    collate_fn=DataCollator(copy_inputs_as_labels=True),\n",
    "    args=train_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=5)] # Early Stopping patience 자유롭게 변경\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model.\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model did not return a loss from the inputs, only the following keys: logits,past_key_values. For reference, the inputs it received are input_ids,attention_mask.\n",
    "# 이런 에러가 나면서 학습이 안될 경우, Trainer 클래스를 상속받아서 loss 계산하는 함수를 오버라이드 해주면 됩니다.\n",
    "\n",
    "# 아래는 loss 계산하는 함수를 오버라이드 하는 예시입니다.\n",
    "# class CustomTrainer(Trainer):\n",
    "#     def compute_loss(self, model, inputs, return_outputs=False):\n",
    "#         labels = inputs.pop(\"labels\")\n",
    "#         outputs = model(**inputs)\n",
    "#         logits = outputs.logits\n",
    "#         loss_fct = torch.nn.CrossEntropyLoss()\n",
    "#         loss = loss_fct(logits.view(-1, logits.size(-1)), labels.view(-1))\n",
    "#         return (loss, outputs) if return_outputs else loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m(train_dataset[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model(train_dataset[0]['input_ids'].unsqueeze(0).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lakh-gpt2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
